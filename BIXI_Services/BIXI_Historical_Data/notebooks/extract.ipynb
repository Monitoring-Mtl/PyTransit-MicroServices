{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pymongo.server_api import ServerApi\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIXI_DATA_URL = \"https://bixi.com/en/open-data\"\n",
    "BIXI_CDN = \"https://s3.ca-central-1.amazonaws.com/cdn.bixi.com/\"\n",
    "MONGO_URI = os.getenv(\"PYTRANSIT_MONGO_URI\")\n",
    "BIXI_DB_NAME = os.getenv(\"BIXI_DB_NAME\")\n",
    "BIXI_HISTORIC_URLS_COLLECTION = os.getenv(\"BIXI_HISTORIC_URLS_COLLECTION\")\n",
    "DEFAULT_ZIP_PATH = \"data/file.zip\"\n",
    "DEFAULT_EXTRACT_PATH = \"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the current urls from the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bixi_historic_data_urls(url=BIXI_DATA_URL):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    urls = [a['href'] for a in soup.find_all('a', href=True) if BIXI_CDN in a['href']]\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://s3.ca-central-1.amazonaws.com/cdn.bixi.com/wp-content/uploads/2024/03/DonneesOuvertes2024_0102.zip',\n",
      " 'https://s3.ca-central-1.amazonaws.com/cdn.bixi.com/wp-content/uploads/2024/01/DonneesOuvertes2023_12.zip',\n",
      " 'https://s3.ca-central-1.amazonaws.com/cdn.bixi.com/wp-content/uploads/2023/08/DonneesOuverte2022.zip',\n",
      " 'https://s3.ca-central-1.amazonaws.com/cdn.bixi.com/wp-content/uploads/2023/06/Historique-BIXI-2021.zip',\n",
      " 'https://s3.ca-central-1.amazonaws.com/cdn.bixi.com/wp-content/uploads/2023/06/Historique-BIXI-2020.zip',\n",
      " 'https://s3.ca-central-1.amazonaws.com/cdn.bixi.com/wp-content/uploads/2023/06/Historique-BIXI-2019.zip',\n",
      " 'https://s3.ca-central-1.amazonaws.com/cdn.bixi.com/wp-content/uploads/2023/06/Historique-BIXI-2018.zip',\n",
      " 'https://s3.ca-central-1.amazonaws.com/cdn.bixi.com/wp-content/uploads/2023/06/Historique-BIXI-2017.zip',\n",
      " 'https://s3.ca-central-1.amazonaws.com/cdn.bixi.com/wp-content/uploads/2023/06/Historique-BIXI-2016.zip',\n",
      " 'https://s3.ca-central-1.amazonaws.com/cdn.bixi.com/wp-content/uploads/2023/06/Historique-BIXI-2015.zip',\n",
      " 'https://s3.ca-central-1.amazonaws.com/cdn.bixi.com/wp-content/uploads/2023/06/Historique-BIXI-2014.zip']\n"
     ]
    }
   ],
   "source": [
    "urls = extract_bixi_historic_data_urls()\n",
    "pprint(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the urls in mongo for later comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_bixi_urls_in_mongodb(urls):\n",
    "    client = MongoClient(MONGO_URI, server_api=ServerApi('1'))\n",
    "    db = client[BIXI_DB_NAME]\n",
    "    collection = db[BIXI_HISTORIC_URLS_COLLECTION]\n",
    "    for url in urls:\n",
    "        document = {\"date_added\": datetime.now()}\n",
    "        collection.replace_one({\"_id\": url}, document, upsert=True)\n",
    "    print(f\"{len(urls)} urls saved.\")\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 urls saved.\n"
     ]
    }
   ],
   "source": [
    "save_bixi_urls_in_mongodb(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For good measure\n",
    "def delete_bixi_urls_from_mongodb(urls):\n",
    "    client = MongoClient(MONGO_URI, server_api=ServerApi('1'))\n",
    "    db = client[BIXI_DB_NAME]\n",
    "    collection = db[BIXI_HISTORIC_URLS_COLLECTION]\n",
    "    for url in urls:\n",
    "        collection.delete_one({\"_id\": url})\n",
    "    print(f\"{len(urls)} urls deleted.\")\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 urls deleted.\n"
     ]
    }
   ],
   "source": [
    "delete_bixi_urls_from_mongodb(urls[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we know we have new data?\n",
    "\n",
    "If we don't have the url saved in our db, we can assume it is new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_new_data(urls):\n",
    "    client = MongoClient(MONGO_URI, server_api=ServerApi('1'))\n",
    "    db = client[BIXI_DB_NAME]\n",
    "    collection = db[BIXI_HISTORIC_URLS_COLLECTION]\n",
    "    existing_urls = {document['_id'] for document in collection.find({}, {'_id': 1})}\n",
    "    new_urls = [url for url in urls if url not in existing_urls]\n",
    "    client.close()\n",
    "    return new_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://s3.ca-central-1.amazonaws.com/cdn.bixi.com/wp-content/uploads/2024/03/DonneesOuvertes2024_0102.zip',\n",
      " 'https://s3.ca-central-1.amazonaws.com/cdn.bixi.com/wp-content/uploads/2024/01/DonneesOuvertes2023_12.zip']\n"
     ]
    }
   ],
   "source": [
    "new_urls = check_new_data(urls)\n",
    "pprint(new_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the data\n",
    "\n",
    "In this notebook we are designing the extraction step, but we should think ahead about the whole process to get an idea of a viable architecture.\n",
    "\n",
    "The workload is as follows:\n",
    "- check for new data url\n",
    "- download a ~500MB zip file from internet\n",
    "- unzip it to a ~2GB file\n",
    "- perform various transformations\n",
    "- load into mongodb\n",
    "- repeat all the above once a month\n",
    "\n",
    "The initial assessment is that this workload is too heavy for lambdas. An on-demand EC2 instance is more appropriate. It could be triggered by EventBridge once a month, execute the steps and shutdown. We need to test the process and estimate the duration on a modest machine like a raspberry pi. This would help in estimating the cost as well.\n",
    "\n",
    "Downloading script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, output_path=DEFAULT_ZIP_PATH):\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with requests.get(url) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(output_path, \"wb\") as file:\n",
    "            file.write(r.content)\n",
    "            print(f\"successful download: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful download: data/file.zip\n"
     ]
    }
   ],
   "source": [
    "download_file(urls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resource utilization while running `download_file` on raspberry pi:\n",
    "```bash\n",
    "(myenv) âžœ  pytransit-bixi-extract du -sh . && /usr/bin/time -v python script.py \"https://s3.ca-central-1.amazonaws.com/cdn.bixi.com/wp-content/uploads/2024/01/DonneesOuvertes2023_12.zip\" && du -sh .\n",
    "31M     .\n",
    "successful download: data/file.zip\n",
    "        Command being timed: \"python script.py https://s3.ca-central-1.amazonaws.com/cdn.bixi.com/wp-content/uploads/2024/01/DonneesOuvertes2023_12.zip\"\n",
    "        User time (seconds): 10.51\n",
    "        System time (seconds): 7.22\n",
    "        Percent of CPU this job got: 51%\n",
    "        Elapsed (wall clock) time (h:mm:ss or m:ss): 0:34.48\n",
    "        Average shared text size (kbytes): 0\n",
    "        Average unshared data size (kbytes): 0\n",
    "        Average stack size (kbytes): 0\n",
    "        Average total size (kbytes): 0\n",
    "        Maximum resident set size (kbytes): 840532\n",
    "        Average resident set size (kbytes): 0\n",
    "        Major (requiring I/O) page faults: 0\n",
    "        Minor (reclaiming a frame) page faults: 207913\n",
    "        Voluntary context switches: 169791\n",
    "        Involuntary context switches: 606\n",
    "        Swaps: 0\n",
    "        File system inputs: 0\n",
    "        File system outputs: 726320\n",
    "        Socket messages sent: 0\n",
    "        Socket messages received: 0\n",
    "        Signals delivered: 0\n",
    "        Page size (bytes): 4096\n",
    "        Exit status: 0\n",
    "385M    .\n",
    "```\n",
    "\n",
    "It shows that, for downloading `DonneesOuvertes2023_12.zip`, we used \n",
    "- `840.5MB` of memory\n",
    "- `51%` of CPU (Raspberry Pi has 4 cores)\n",
    "- about `350MB` of disk space\n",
    "- about `34 seconds` to complete (on ~10MBps internet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have to decompress the downloaded zip file. To save disk space, we could bypass writing the zip on disk and start decompressing directly. But that would take up more memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_extract_zip(url, extract_path=DEFAULT_EXTRACT_PATH):\n",
    "    os.makedirs(extract_path, exist_ok=True)\n",
    "    with requests.get(url) as r:\n",
    "        r.raise_for_status()\n",
    "        with zipfile.ZipFile(BytesIO(r.content)) as z:\n",
    "            z.extractall(path=extract_path)\n",
    "            print(f\"File extracted to: {extract_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File extracted to: data/\n"
     ]
    }
   ],
   "source": [
    "download_and_extract_zip(urls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resource utilization:\n",
    "\n",
    "```bash\n",
    "(myenv) âžœ  pytransit-bixi-extract du -sh . && /usr/bin/time -v python script.py \"https://s3.ca-central-1.amazonaws.com/cdn.bixi.com/wp-content/uploads/2024/01/DonneesOuvertes2023_12.zip\" && du -sh .\n",
    "31M     .\n",
    "Files extracted to: data/\n",
    "        Command being timed: \"python script.py https://s3.ca-central-1.amazonaws.com/cdn.bixi.com/wp-content/uploads/2024/01/DonneesOuvertes2023_12.zip\"\n",
    "        User time (seconds): 28.01\n",
    "        System time (seconds): 14.02\n",
    "        Percent of CPU this job got: 34%\n",
    "        Elapsed (wall clock) time (h:mm:ss or m:ss): 2:02.76\n",
    "        Average shared text size (kbytes): 0\n",
    "        Average unshared data size (kbytes): 0\n",
    "        Average stack size (kbytes): 0\n",
    "        Average total size (kbytes): 0\n",
    "        Maximum resident set size (kbytes): 796724\n",
    "        Average resident set size (kbytes): 0\n",
    "        Major (requiring I/O) page faults: 0\n",
    "        Minor (reclaiming a frame) page faults: 197010\n",
    "        Voluntary context switches: 167507\n",
    "        Involuntary context switches: 2749\n",
    "        Swaps: 0\n",
    "        File system inputs: 0\n",
    "        File system outputs: 3823184\n",
    "        Socket messages sent: 0\n",
    "        Socket messages received: 0\n",
    "        Signals delivered: 0\n",
    "        Page size (bytes): 4096\n",
    "        Exit status: 0\n",
    "1.9G    .\n",
    "```\n",
    "\n",
    "This shows that, for downloading and decompressing `DonneesOuvertes2023_12.zip`, we used:\n",
    "- `796.7MB` of memory\n",
    "- `34%` of CPU\n",
    "- `~1.9GB` of disk space\n",
    "- a little over `2 minutes` of running time\n",
    "\n",
    "After analyzing this, we can see that the extraction workload is not actually so heavy for lambdas if not for the disk space. We can imagine a scenario where, a 1024MB Lambda runs the `download_and_extract_zip` function and saves the decompressed file into a S3 bucket. Then other Lambdas would read from the S3 bucket for the `Transform` and `Load` steps and perform a cleanup afterwards.\n",
    "\n",
    "Another alternative, as mentioned before is to use an on-demand EC2 instance with a EBS attachment for storage to take care of the whole process.\n",
    "\n",
    "We can also explore AWS batch. We probably should test the rest of the ETL process to get a better picture of the architectural requirements.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytransit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
